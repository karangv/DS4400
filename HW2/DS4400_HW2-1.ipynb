{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab3d047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Mean  Std Dev\n",
      "bedrooms        0.0      1.0\n",
      "bathrooms      -0.0      1.0\n",
      "sqft_living     0.0      1.0\n",
      "sqft_lot        0.0      1.0\n",
      "floors         -0.0      1.0\n",
      "waterfront      0.0      1.0\n",
      "view            0.0      1.0\n",
      "condition      -0.0      1.0\n",
      "grade           0.0      1.0\n",
      "sqft_above      0.0      1.0\n",
      "sqft_basement   0.0      1.0\n",
      "yr_built        0.0      1.0\n",
      "yr_renovated    0.0      1.0\n",
      "lat             0.0      1.0\n",
      "long           -0.0      1.0\n",
      "sqft_living15   0.0      1.0\n",
      "sqft_lot15     -0.0      1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset and standardize the features\n",
    "df = pd.read_csv('kc_house_data.csv')\n",
    "features = df.drop(columns=['id', 'date', 'zipcode', 'price'])\n",
    "response = df['price']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = features.select_dtypes(include=[np.number]).columns\n",
    "features[numeric_cols] = scaler.fit_transform(features[numeric_cols])\n",
    "response = response / 1000\n",
    "\n",
    "# Mean and standard deviation of the features\n",
    "stats = pd.DataFrame({\n",
    "    'Mean': features[numeric_cols].mean().round(6),\n",
    "    'Std Dev': features[numeric_cols].std(ddof=0).round(6)\n",
    "})\n",
    "\n",
    "print(stats.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79afc2d2",
   "metadata": {},
   "source": [
    "# Problem 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17b32b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 539.5055872959464\n",
      "Coefficients:\n",
      " bedrooms         -30.513682\n",
      "bathrooms         35.066808\n",
      "sqft_living       79.938617\n",
      "sqft_lot           3.507234\n",
      "floors             0.798518\n",
      "waterfront        49.152517\n",
      "view              38.697517\n",
      "condition         18.732037\n",
      "grade            112.491578\n",
      "sqft_above        74.960699\n",
      "sqft_basement     25.633206\n",
      "yr_built         -74.370988\n",
      "yr_renovated       8.863557\n",
      "lat               77.143288\n",
      "long             -14.308256\n",
      "sqft_living15     18.286243\n",
      "sqft_lot15        -9.025491\n",
      "dtype: float64\n",
      "\n",
      "MSE: 39834.25349762571\n",
      "R²: 0.6951038946870624\n",
      "\n",
      "Test MSE: 45998.56287706282\n",
      "Test R²: 0.6957298370207377\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets, and fit a linear regression model\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, response, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on training data\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "# Coefficients\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Coefficients:\\n\", pd.Series(model.coef_, index=X_train.columns))\n",
    "\n",
    "# Metrics on training data\n",
    "print(\"\\nMSE:\", mean_squared_error(y_train, y_pred))\n",
    "print(\"R²:\", r2_score(y_train, y_pred))\n",
    "\n",
    "# Metrics on test data\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"\\nTest MSE:\", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Test R²:\", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275ae218",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd889e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 539.5055872959458\n",
      "Coefficients:\n",
      " bedrooms         -30.513682\n",
      "bathrooms         35.066808\n",
      "sqft_living       79.938617\n",
      "sqft_lot           3.507234\n",
      "floors             0.798518\n",
      "waterfront        49.152517\n",
      "view              38.697517\n",
      "condition         18.732037\n",
      "grade            112.491578\n",
      "sqft_above        74.960699\n",
      "sqft_basement     25.633206\n",
      "yr_built         -74.370988\n",
      "yr_renovated       8.863557\n",
      "lat               77.143288\n",
      "long             -14.308256\n",
      "sqft_living15     18.286243\n",
      "sqft_lot15        -9.025491\n",
      "dtype: float64\n",
      "\n",
      "Training MSE: 39834.2534976257\n",
      "Training R²: 0.6951038946870625\n",
      "\n",
      "Test MSE: 45998.56287706284\n",
      "Test R²: 0.6957298370207374\n"
     ]
    }
   ],
   "source": [
    "# Add a column of ones for the intercept term\n",
    "X_train_b = np.column_stack([np.ones(X_train.shape[0]), X_train])\n",
    "X_test_b = np.column_stack([np.ones(X_test.shape[0]), X_test])\n",
    "\n",
    "# Closed-form solution\n",
    "def fit_linear_regression(X, y):\n",
    "    beta = np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "    return beta\n",
    "\n",
    "# Predict function\n",
    "def predict(X, beta):\n",
    "    return X @ beta\n",
    "\n",
    "# Train the model\n",
    "beta = fit_linear_regression(X_train_b, y_train)\n",
    "\n",
    "# Extract intercept and coefficients\n",
    "print(\"Intercept:\", beta[0])\n",
    "print(\"Coefficients:\\n\", pd.Series(beta[1:], index=X_train.columns))\n",
    "\n",
    "# Predictions and metrics on training set\n",
    "y_train_pred = predict(X_train_b, beta)\n",
    "print(\"\\nTraining MSE:\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Training R²:\", r2_score(y_train, y_train_pred))\n",
    "\n",
    "# Predictions and metrics on testing set\n",
    "y_test_pred = predict(X_test_b, beta)\n",
    "print(\"\\nTest MSE:\", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Test R²:\", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d5d2f",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52550b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Degree  Train MSE  Train R²   Test MSE  Test R²\n",
      "      1 66319.3478    0.4924 76484.9771   0.4941\n",
      "      2 58871.8551    0.5494 82113.9312   0.4568\n",
      "      3 58862.5290    0.5495 83663.5267   0.4466\n",
      "      4 58818.3044    0.5498 88922.1679   0.4118\n",
      "      5 58798.9524    0.5499 88307.6469   0.4159\n"
     ]
    }
   ],
   "source": [
    "# Polynomial regression using closed-form solution\n",
    "\n",
    "def polynomial_features(X, degree):\n",
    "    X = np.array(X).reshape(-1, 1)\n",
    "    return np.hstack([X ** i for i in range(1, degree + 1)])\n",
    "\n",
    "def fit_linear_regression(X, y):\n",
    "    beta, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n",
    "    return beta\n",
    "\n",
    "def predict(X, beta):\n",
    "    return X @ beta\n",
    "\n",
    "# Use sqft_living as the single feature (unstandardized, from original df)\n",
    "X_single = df['sqft_living']\n",
    "y = df['price'].values / 1000\n",
    "\n",
    "# Split using the same random state\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_single, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate for different polynomial degrees\n",
    "results = []\n",
    "degrees = [1, 2, 3, 4, 5]\n",
    "\n",
    "for p in degrees:\n",
    "    # Create polynomial features and add intercept column\n",
    "    X_train_poly = polynomial_features(X_train_s, p)\n",
    "    X_test_poly = polynomial_features(X_test_s, p)\n",
    "\n",
    "    # Standardize polynomial features\n",
    "    scaler_poly = StandardScaler()\n",
    "    X_train_poly = scaler_poly.fit_transform(X_train_poly)\n",
    "    X_test_poly = scaler_poly.transform(X_test_poly)\n",
    "\n",
    "    # Add intercept column of ones\n",
    "    X_train_poly = np.column_stack([np.ones(X_train_poly.shape[0]), X_train_poly])\n",
    "    X_test_poly = np.column_stack([np.ones(X_test_poly.shape[0]), X_test_poly])\n",
    "\n",
    "    # Fit model\n",
    "    beta = fit_linear_regression(X_train_poly, y_train_s)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = predict(X_train_poly, beta)\n",
    "    y_test_pred = predict(X_test_poly, beta)\n",
    "    \n",
    "    # Metrics\n",
    "    train_mse = mean_squared_error(y_train_s, y_train_pred)\n",
    "    train_r2 = r2_score(y_train_s, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test_s, y_test_pred)\n",
    "    test_r2 = r2_score(y_test_s, y_test_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Degree': p,\n",
    "        'Train MSE': round(train_mse, 4),\n",
    "        'Train R²': round(train_r2, 4),\n",
    "        'Test MSE': round(test_mse, 4),\n",
    "        'Test R²': round(test_r2, 4)\n",
    "    })\n",
    "\n",
    "# Display results as a table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e55dbaf",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d708e807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Alpha  Iterations    Train MSE      Train R²     Test MSE       Test R²\n",
      "  0.01          10 3.237865e+05 -1.478300e+00 3.474337e+05 -1.298200e+00\n",
      "  0.01          50 1.563500e+05 -1.967000e-01 1.684999e+05 -1.146000e-01\n",
      "  0.01         100 8.256856e+04  3.680000e-01 9.157093e+04  3.943000e-01\n",
      "  0.10          10 7.865950e+04  3.979000e-01 8.745376e+04  4.215000e-01\n",
      "  0.10          50 4.000497e+04  6.938000e-01 4.620990e+04  6.943000e-01\n",
      "  0.10         100 3.984818e+04  6.950000e-01 4.599980e+04  6.957000e-01\n",
      "  0.50          10 2.213264e+08 -1.693058e+03 2.390183e+08 -1.580052e+03\n",
      "  0.50          50 7.336029e+22 -5.615084e+17 7.919689e+22 -5.238696e+17\n",
      "  0.50         100 1.037753e+41 -7.943084e+35 1.120317e+41 -7.410647e+35\n"
     ]
    }
   ],
   "source": [
    "# Gradient Descent for Linear Regression\n",
    "def gradient_descent(X, y, alpha, n_iters):\n",
    "  \n",
    "    N = X.shape[0]\n",
    "    theta = np.zeros(X.shape[1])  # Initialize theta to zeros\n",
    "    history = {}\n",
    "\n",
    "    for i in range(1, n_iters + 1):\n",
    "        y_pred = X @ theta\n",
    "        \n",
    "        gradient = (1 / N) * (X.T @ (y_pred - y))\n",
    "       \n",
    "        theta = theta - alpha * gradient\n",
    "\n",
    "        # Save theta at specific iterations\n",
    "        if i in [10, 50, 100]:\n",
    "            history[i] = theta.copy()\n",
    "\n",
    "    return theta, history\n",
    "\n",
    "def predict(X, theta):\n",
    "    return X @ theta\n",
    "\n",
    "# Use the same standardized training/testing data\n",
    "# Add intercept column of ones\n",
    "X_train_b = np.column_stack([np.ones(X_train.shape[0]), X_train])\n",
    "X_test_b = np.column_stack([np.ones(X_test.shape[0]), X_test])\n",
    "\n",
    "# Learning rates and iterations to test\n",
    "learning_rates = [0.01, 0.1, 0.5]\n",
    "checkpoints = [10, 50, 100]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for alpha in learning_rates:\n",
    "    theta, history = gradient_descent(X_train_b, y_train.values, alpha, 100)\n",
    "\n",
    "    for iters in checkpoints:\n",
    "        t = history[iters]\n",
    "\n",
    "        # Predictions\n",
    "        y_train_pred = predict(X_train_b, t)\n",
    "        y_test_pred = predict(X_test_b, t)\n",
    "\n",
    "        # Metrics\n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "        results.append({\n",
    "            'Alpha': alpha,\n",
    "            'Iterations': iters,\n",
    "            'Train MSE': round(train_mse, 4),\n",
    "            'Train R²': round(train_r2, 4),\n",
    "            'Test MSE': round(test_mse, 4),\n",
    "            'Test R²': round(test_r2, 4)\n",
    "        })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febda2cc",
   "metadata": {},
   "source": [
    "# Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d26d97c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Intercept   Slope     MSE     R^2\n",
      "Method                                              \n",
      "Linear Regression     1.0442  1.8730  4.0092  0.5359\n",
      "Ridge (lam=1)         1.0443  1.8716  4.0092  0.5359\n",
      "Ridge (lam=10)        1.0442  1.8589  4.0095  0.5359\n",
      "Ridge (lam=100)       1.0433  1.7411  4.0322  0.5333\n",
      "Ridge (lam=1000)      1.0384  1.0656  4.8696  0.4364\n",
      "Ridge (lam=10000)     1.0322  0.2184  7.6227  0.1177\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def ridge_gradient_descent(X, y, alpha, n_iters, lam):\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    for i in range(1, n_iters + 1):\n",
    "        y_pred = X @ theta\n",
    "        reg_term = 2 * lam * theta\n",
    "        reg_term[0] = 0\n",
    "        gradient = 2 * (X.T @ (y_pred - y)) + reg_term\n",
    "        theta = theta - alpha * gradient\n",
    "    return theta\n",
    "\n",
    "# Metrics\n",
    "\n",
    "def mse(X, y, theta):\n",
    "    y_pred = X @ theta\n",
    "    return float(np.mean((y_pred - y) ** 2))\n",
    "\n",
    "def r2(X, y, theta):\n",
    "    y_pred = X @ theta\n",
    "    ss_res = float(np.sum((y - y_pred) ** 2))\n",
    "    ss_tot = float(np.sum((y - np.mean(y)) ** 2))\n",
    "    return 1 - ss_res / ss_tot\n",
    "\n",
    "# Simulate Data\n",
    "\n",
    "np.random.seed(100)\n",
    "N = 1000\n",
    "\n",
    "X_raw = np.random.uniform(-2, 2, N)\n",
    "e = np.random.normal(0, 2, N)\n",
    "y = 1 + 2 * X_raw + e\n",
    "\n",
    "# Add bias column\n",
    "X = np.hstack([np.ones(N).reshape(-1, 1), X_raw.reshape(-1, 1)])\n",
    "\n",
    "# Fit Linear Regression \n",
    "\n",
    "alpha = 0.001\n",
    "n_iters = 10000\n",
    "\n",
    "theta_ols, _ = gradient_descent(X, y, alpha, n_iters)\n",
    "theta_ols = theta_ols.flatten()\n",
    "\n",
    "results = []\n",
    "\n",
    "results.append({\n",
    "    \"Method\": \"Linear Regression\",\n",
    "    \"Intercept\": theta_ols[0],\n",
    "    \"Slope\": theta_ols[1],\n",
    "    \"MSE\": mse(X, y, theta_ols),\n",
    "    \"R^2\": r2(X, y, theta_ols)\n",
    "})\n",
    "\n",
    "# Fit Ridge Regression for different lambdas\n",
    "\n",
    "lambdas = [1, 10, 100, 1000, 10000]\n",
    "n_iters_ridge = 50000\n",
    "\n",
    "for lam in lambdas:\n",
    "    alpha_ridge = 1 / (4 * (N + lam))\n",
    "    theta_ridge = ridge_gradient_descent(X, y, alpha_ridge, n_iters_ridge, lam)\n",
    "    theta_ridge = theta_ridge.flatten()\n",
    "\n",
    "    results.append({\n",
    "        \"Method\": \"Ridge (lam={})\".format(lam),\n",
    "        \"Intercept\": theta_ridge[0],\n",
    "        \"Slope\": theta_ridge[1],\n",
    "        \"MSE\": mse(X, y, theta_ridge),\n",
    "        \"R^2\": r2(X, y, theta_ridge)\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results).set_index(\"Method\")\n",
    "print(df.round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
